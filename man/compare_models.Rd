% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compare_models.R, R/modeling_phrases.R
\name{compare_models.lm}
\alias{compare_models.lm}
\alias{compare_models.glm}
\alias{compare_models}
\title{Compute a p-value comparing two nested models.}
\usage{
\method{compare_models}{lm}(
  full.mean.model,
  reduced.mean.model,
  alternative = c("ne", "not equal", "!=", "lt", "less than", "<", "gt", "greater than",
    ">", "at least one differs"),
  simulation.replications = 4999,
  assume.constant.variance = TRUE,
  assume.normality = FALSE,
  construct = c("normal-2", "normal-1", "two-point mass"),
  ...
)

\method{compare_models}{glm}(
  full.mean.model,
  reduced.mean.model,
  alternative = c("ne", "not equal", "!=", "lt", "less than", "<", "gt", "greater than",
    ">", "at least one differs"),
  simulation.replications = 4999,
  method = c("classical", "parametric"),
  ...
)

compare_models(
  full.mean.model,
  reduced.mean.model,
  alternative = c("ne", "not equal", "!=", "lt", "less than", "<", "gt", "greater than",
    ">", "at least one differs"),
  simulation.replications = 4999,
  ...
)
}
\arguments{
\item{full.mean.model}{\code{lm} or \code{glm} model object defining the
full model.}

\item{reduced.mean.model}{model object of the same type as
\code{full.mean.model} defining the reduced model under the null hypothesis.}

\item{alternative}{characterizes the form of the alternative hypothesis; one
of \code{'not equal'} (\code{'ne'}, \code{'!='}), indicating a two-sided
alternative; \code{'less than'} (\code{'lt'}, \code{'<'}), indicating a
one-sided alternative where the parameter is less than the specified null
value; or \code{'greater than'} (\code{'gt'}, \code{'>'}), indicating a
one-sided alternative where the parameter is greater than the specified null
value. This only applies when the reduced model under the null hypothesis
differs from the full model by a single specified parameter. Otherwise,
a two-sided test is performed (\code{'at least one differs'}, the standard
ANOVA alternative).}

\item{simulation.replications}{scalar indicating the number of samples to
draw from the model for the null distribution (default = 4999). This will
either be the number of bootstrap relications or the number of samples from
the classical null distribution.}

\item{assume.constant.variance}{boolean; if \code{TRUE} (default), all errors
are assumed to have the same variance. If \code{FALSE}, each error is
allowed to have a different variance.}

\item{assume.normality}{boolean; if \code{TRUE}, the errors are assumed to
follow a Normal distribution. If \code{FALSE} (default), this is not
assumed.}

\item{construct}{string defining the type of construct to use when generating
from the distribution for the wild bootstrap (see \code{\link{rmammen}}). If
\code{assume.constant.variance = TRUE}, this is ignored
(default = \code{"normal-2"}).}

\item{...}{additional arguments to be passed to other methods.}

\item{method}{string defining the methodology to employ. If
\code{"classical"} (default), the model is assumed correct and classical
large-sample theory is used. If \code{"parametric"}, a parametric bootstrap
is performed.}
}
\value{
data.frame containing an ANOVA table comparing the two models. The
data.frame has a single attribute "Null Distribution" which is a numeric
vector of length \code{simulation.replications} which
contains a sample from the model of the null distribution of the test
statistic. This is useful for plotting the null distribution.
}
\description{
Tests whether a reduced (nested) model is sufficient for explaining the
variability in the response compared to a more complex model.
}
\details{
This wrapper provides a single interface for commparing models under various
conditions imposed on the model. Similar to \code{\link[stats]{anova}}.
Howevever, the p-value provided can be computed using classical methods or
bootstrapping.

For linear models, the following approaches are implemented:
\itemize{
  \item classical: if both homoskedasticity and normality are assumed, the
sampling distributions of a standardized statistic is modeled by an
F-distribution.
  \item parametric bootstrap: if normality can be assumed but
homoskedasticity cannot, a parametric bootstrap can be peformed in which the
variance for each observation is estimated by the square of the corresponding
residual (similar to a White's correction).
  \item residual bootstrap: if homoskedasticity can be assumed, but normality
cannot, a residual bootstrap is used to compute the p-value.
  \item wild bootstrap: if neither homoskedasticity nor normality is assumed,
a wild bootstrap is used to compute the p-value.
}
All methods make additional requirements regarding independence of the error
terms and that the model has been correctly specified.

For generalized linear models, the following approaches are implemented:
\itemize{
  \item classical: if the distributional family is assumed correct, large
  sample theory is used to justify modeling the sampling distribution of a
  standardized statistic using a chi-squared distribution.
  \item parametric bootstrap: the distributional family is assumed and
  a parametric bootstrap is performed to compute the p-value.
}
All methods require observations to be independent of one another.
}
\section{Methods (by class)}{
\itemize{
\item \code{compare_models(lm)}: Computes p-value comparing nested linear models.

\item \code{compare_models(glm)}: Computes p-value comparing nested generalized
linear models.

}}
\examples{
fit1 <- lm(mpg ~ 1 + hp, data = mtcars)
fit0 <- lm(mpg ~ 1, data = mtcars)

# p-value computed via residual bootstrap
compare_models(fit1, fit0,
  assume.constant.variance = TRUE,
  assume.normality = FALSE)

# classical inference
compare_models(fit1, fit0,
  assume.constant.variance = TRUE,
  assume.normality = TRUE)


}
\seealso{
\code{\link[stats]{anova}}
}
